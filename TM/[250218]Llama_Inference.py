import torch
import re
from transformers import AutoTokenizer, AutoModelForCausalLM
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# âœ… 1. ëª¨ë¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
model_path = "./fine_tuned_llama_text"
device = "cuda" if torch.cuda.is_available() else "cpu"

# âœ… Fine-Tuned LLaMA ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(model_path)
llama_model = AutoModelForCausalLM.from_pretrained(
    model_path, torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
).to(device)

print("âœ… Fine-Tuned LLaMA ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

# âœ… FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vector_db = FAISS.load_local("faiss_gripper_db", embedding_model, allow_dangerous_deserialization=True)
print("âœ… FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")

# âœ… 2. ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
text_input = input("ğŸ“ Enter a description of the object: ").strip()

# âœ… 3. FAISSë¥¼ ì´ìš©í•´ ê°€ì¥ ê´€ë ¨ ìˆëŠ” ë¬¸ì„œ ê²€ìƒ‰
retrieved_docs = vector_db.similarity_search(text_input, k=1)
context = retrieved_docs[0].page_content if retrieved_docs else ""

# âœ… 4. ëª¨ë¸ ì…ë ¥ êµ¬ì„± (ê²€ìƒ‰ëœ ë¬¸ë§¥ ì¶”ê°€)
combined_prompt = f"Context: {context}\n\n{text_input}"

# âœ… 5. í† í¬ë‚˜ì´ì§•
inputs = tokenizer(
    combined_prompt,
    return_tensors="pt",
    padding=True,
    truncation=True,
    max_length=256
).to(device)

# âœ… 6. ëª¨ë¸ ì¶”ë¡ 
print("ğŸ”¹ Processing text input...")

with torch.no_grad():
    output_tokens = llama_model.generate(
        input_ids=inputs["input_ids"],
        attention_mask=inputs["attention_mask"],
        max_new_tokens=100,  # âœ… ì¶©ë¶„í•œ ë¬¸ì¥ ê¸¸ì´ í™•ë³´
        do_sample=False,  # âœ… ì•ˆì •ì ì¸ ê²°ê³¼ ìƒì„±
        pad_token_id=tokenizer.pad_token_id  
    )

gripper_response = tokenizer.decode(output_tokens[0], skip_special_tokens=True)

print(gripper_response)
# âœ… 7. í›„ì²˜ë¦¬: ì¶”ì²œëœ ê·¸ë¦¬í¼ ì¶”ì¶œ
valid_grippers = ["Suction Gripper", "Parallel Jaw Gripper", "Magnetic Gripper"]
pattern = "|".join(map(re.escape, valid_grippers))

match = re.search(pattern, gripper_response)
recommended_gripper = match.group(0) if match else "Unknown"

# âœ… 8. ìµœì¢… ì¶œë ¥
print("\nğŸ”¹ **LLaMA Model Prediction:**")
print(f"ğŸ“ Object Description: {text_input}")
print(f"âœ… Recommended Gripper: {recommended_gripper}")
print(f"ğŸ’¡ Explanation: {gripper_response}")

# âœ… 9. FAISS ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
print("\nğŸ”¹ **Retrieved Context from FAISS:**")
print(context)
