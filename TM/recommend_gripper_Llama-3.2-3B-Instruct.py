import torch
import os
import json
import shutil
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch.nn as nn
import torch.optim as optim
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings

# 1. ëª¨ë¸ ë° ë””ë°”ì´ìŠ¤ ì„¤ì •
model_name = "meta-llama/Llama-3.2-3B-Instruct"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
HUGGINGFACE_TOKEN = "test Token"

# Fine-Tuned Llama ëª¨ë¸ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(model_name, token=HUGGINGFACE_TOKEN)
llama_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
    token=HUGGINGFACE_TOKEN
).to(device)

# í† í¬ë‚˜ì´ì €ì— pad_token ì¶”ê°€
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.add_special_tokens({'pad_token': '[PAD]'})
    llama_model.resize_token_embeddings(len(tokenizer))

# FAISS ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ ì„¤ì •
db_path = "faiss_gripper_db"

# 2. FAISS ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (í•„ìš” ì‹œ)
if not os.path.exists(db_path):
    print("ğŸ”¹ FAISS ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ. ìƒˆë¡œ ìƒì„± ì¤‘...")
    # Gripper ì •ë³´ ì •ì˜
    documents = [
        "A Suction Gripper is best for soft, round objects like apples. It uses vacuum suction.",
        "A Parallel Jaw Gripper is best for flat, rigid objects like boxes. It uses mechanical clamping.",
        "A Magnetic Gripper is best for metallic objects like rods. It uses magnetism.",
        "A Suction Gripper works well on lightweight, deformable objects like foam balls.",
        "Parallel Jaw Grippers are ideal for securely grasping paper stacks without damaging them.",
        "Magnetic Grippers are commonly used in industrial settings to manipulate metal sheets and rods."
    ]

    # Hugging Face ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    # FAISS ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ë° ì €ì¥
    vector_db = FAISS.from_texts(documents, embedding_model)
    vector_db.save_local(db_path)
    print("âœ… FAISS ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ!")
else:
    # ê¸°ì¡´ FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vector_db = FAISS.load_local(db_path, embedding_model, allow_dangerous_deserialization=True)
    print("âœ… FAISS ë°ì´í„°ë² ì´ìŠ¤ ë¡œë“œ ì™„ë£Œ!")

# 3. ë°ì´í„°ì…‹ ë¡œë“œ
dataset_path = "GripperImages/gripper_dataset.json"

# JSON íŒŒì¼ ë¡œë“œ ë° í˜•ì‹ í™•ì¸
with open(dataset_path, "r", encoding="utf-8") as f:
    dataset_json = json.load(f)

if "image_text_pairs" not in dataset_json:
    raise KeyError("âŒ 'image_text_pairs' keyê°€ JSON íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")

data = dataset_json["image_text_pairs"]
if not isinstance(data, list):
    raise ValueError(f"âŒ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {type(data)}")


# 4. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì •ì˜ (RAG ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•œ ì •ë³´ ì¶”ê°€)
class GripperDataset(Dataset):
    def __init__(self, data, tokenizer, max_length=256):
        self.data = data
        self.tokenizer = tokenizer
        self.max_length = max_length  # ëª¨ë¸ ì…ë ¥ ê¸¸ì´ ë§ì¶”ê¸°

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        if idx >= len(self.data):
            raise IndexError(f"âŒ ì˜ëª»ëœ ì¸ë±ìŠ¤ ì ‘ê·¼: {idx} (ë°ì´í„° ê¸¸ì´: {len(self.data)})")

        item = self.data[idx]

        if "text" not in item or "label" not in item:
            raise KeyError(f"âŒ ë°ì´í„°ì— 'text' ë˜ëŠ” 'label' í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {item}")

        # RAG ê²€ìƒ‰: ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        retrieved_docs = vector_db.similarity_search(item["text"], k=1)
        context = retrieved_docs[0].page_content if retrieved_docs else ""

        # ì…ë ¥ í…ìŠ¤íŠ¸: ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ í¬í•¨í•˜ì—¬ í•™ìŠµ
        input_text = f"Context: {context}\n\n{item['text']}"
        output_text = f"{item['label']}"

        # í† í° ë³€í™˜ (ì…ë ¥ê³¼ ì •ë‹µ ëª¨ë‘ ë™ì¼í•œ max_length ì ìš©)
        input_ids = tokenizer(
            input_text,
            return_tensors="pt",
            padding="max_length",
            max_length=self.max_length,
            truncation=True
        )

        label_ids = tokenizer(
            output_text,
            return_tensors="pt",
            padding="max_length",
            max_length=self.max_length,
            truncation=True
        )

        labels = label_ids["input_ids"].squeeze(0)

        # ğŸ”¹ Padding í† í°ì€ ì†ì‹¤ ê³„ì‚°ì—ì„œ ì œì™¸í•˜ê¸° ìœ„í•´ ignore_index=-100 ì„¤ì •
        labels[labels == tokenizer.pad_token_id] = -100

        return {
            "input_ids": input_ids["input_ids"].squeeze(0),
            "labels": labels
        }


# ë°ì´í„°ì…‹ ë° DataLoader ì„¤ì •
dataset = GripperDataset(data, tokenizer, max_length=256)
dataloader = DataLoader(dataset, batch_size=1, shuffle=True)

# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” ê¸°ë²• ì •ì˜
criterion = nn.CrossEntropyLoss(ignore_index=-100)
optimizer = optim.AdamW(llama_model.parameters(), lr=2e-5)

# í•™ìŠµ ë£¨í”„
num_epochs = 3
llama_model.train()

for epoch in range(num_epochs):
    total_loss = 0
    for batch in dataloader:
        inputs = {k: v.to(device) for k, v in batch.items()}

        optimizer.zero_grad()
        outputs = llama_model(
            input_ids=inputs["input_ids"], 
            labels=inputs["labels"]
        )

        loss = outputs.loss
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    print(f"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}")

# ëª¨ë¸ ì €ì¥
save_path = "./fine_tuned_llama_text"
llama_model.save_pretrained(save_path)
tokenizer.save_pretrained(save_path)

print("âœ… Fine-Tuning ì™„ë£Œ ë° ëª¨ë¸ ì €ì¥!")
